\contentsline {chapter}{\numberline {第一章\hspace {0.3em}}序论}{7}
\contentsline {section}{\numberline {1.1}进一步的阅读和总结}{9}
\contentsline {chapter}{\numberline {第二章\hspace {0.3em}}数学准备知识}{11}
\contentsline {section}{\numberline {2.1}矢量分析}{11}
\contentsline {subsection}{\numberline {2.1.1}矢量的模}{11}
\contentsline {subsection}{\numberline {2.1.2}矢量的范数}{11}
\contentsline {section}{\numberline {2.2}矩阵及其基本运算}{12}
\contentsline {subsection}{\numberline {2.2.1}常见的矩阵}{12}
\contentsline {subsection}{\numberline {2.2.2}矩阵的范数}{12}
\contentsline {section}{\numberline {2.3}导数}{13}
\contentsline {subsection}{\numberline {2.3.1}常见的向量导数}{14}
\contentsline {subsection}{\numberline {2.3.2}导数法则}{14}
\contentsline {section}{\numberline {2.4}常用函数}{15}
\contentsline {subsection}{\numberline {2.4.1}logistic/sigmoid函数}{16}
\contentsline {subsection}{\numberline {2.4.2}softmax函数}{16}
\contentsline {subsection}{\numberline {2.4.3}Rectifier函数(ReLU)}{17}
\contentsline {section}{\numberline {2.5}一些练习}{18}
\contentsline {section}{\numberline {2.6}进一步的阅读和总结}{18}
\contentsline {chapter}{\numberline {第三章\hspace {0.3em}}机器学习概述}{19}
\contentsline {section}{\numberline {3.1}机器学习概述}{19}
\contentsline {subsection}{\numberline {3.1.1}补充问题：正则化}{21}
\contentsline {subsection}{\numberline {3.1.2}损失函数}{27}
\contentsline {subsection}{\numberline {3.1.3}补充问题：机器学习与信息论的关系}{28}
\contentsline {subsection}{\numberline {3.1.4}机器学习算法的类型}{30}
\contentsline {subsection}{\numberline {3.1.5}机器学习中的一些基本概念}{32}
\contentsline {subsection}{\numberline {3.1.6}参数学习方法}{33}
\contentsline {section}{\numberline {3.2}线性回归}{36}
\contentsline {section}{\numberline {3.3}线性分类}{36}
\contentsline {subsection}{\numberline {3.3.1}二类分类}{36}
\contentsline {subsection}{\numberline {3.3.2}多类线性分类}{36}
\contentsline {section}{\numberline {3.4}评价方法}{36}
\contentsline {section}{\numberline {3.5}进一步的阅读和总结}{36}
\contentsline {chapter}{\numberline {第四章\hspace {0.3em}}感知器}{37}
\contentsline {section}{\numberline {4.1}二类感知器}{37}
\contentsline {subsection}{\numberline {4.1.1}感知器学习算法}{37}
\contentsline {subsection}{\numberline {4.1.2}线性感知器收敛性证明}{37}
\contentsline {section}{\numberline {4.2}多类感知器}{37}
\contentsline {subsection}{\numberline {4.2.1}多类感知器收敛性证明}{37}
\contentsline {section}{\numberline {4.3}投票感知器}{37}
\contentsline {section}{\numberline {4.4}进一步的阅读和总结}{37}
\contentsline {chapter}{\numberline {第五章\hspace {0.3em}}人工神经网络}{39}
\contentsline {section}{\numberline {5.1}神经元}{40}
\contentsline {subsection}{\numberline {5.1.1}激活函数}{40}
\contentsline {subsection}{\numberline {5.1.2}激活函数的表达能力}{41}
\contentsline {section}{\numberline {5.2}前馈神经网络}{45}
\contentsline {subsection}{\numberline {5.2.1}前馈计算}{45}
\contentsline {section}{\numberline {5.3}反向传播算法}{45}
\contentsline {section}{\numberline {5.4}梯度消失问题}{45}
\contentsline {section}{\numberline {5.5}训练方法}{45}
\contentsline {section}{\numberline {5.6}一些经验}{45}
\contentsline {section}{\numberline {5.7}进一步的阅读和总结}{45}
\contentsline {chapter}{\numberline {第六章\hspace {0.3em}}受限波尔兹曼机RBM}{47}
\contentsline {section}{\numberline {6.1}Roadmap}{47}
\contentsline {section}{\numberline {6.2}Notations}{47}
\contentsline {section}{\numberline {6.3}Energy-Based Models}{48}
\contentsline {section}{\numberline {6.4}An Simple Example of Energy-Based Models}{49}
\contentsline {section}{\numberline {6.5}Introducing Hidden Variables}{49}
\contentsline {section}{\numberline {6.6}Gradient Learning of Energy-based Models}{51}
\contentsline {section}{\numberline {6.7}Boltzmann Machines}{52}
\contentsline {section}{\numberline {6.8}Gradient Learning of Boltzmann Machines}{52}
\contentsline {section}{\numberline {6.9}Gibbs Sampling for Conditional Probability}{53}
\contentsline {section}{\numberline {6.10}Gibbs Sampling for Boltzmann Machines}{53}
\contentsline {section}{\numberline {6.11}Restricted Boltzmann Machines}{54}
\contentsline {section}{\numberline {6.12}Gibbs Sampling for Restricted Boltzmann Machines}{54}
\contentsline {section}{\numberline {6.13}Contrastive Divergence}{55}
\contentsline {section}{\numberline {6.14}Gibbs Sampling和Markov Chain以及MCMC的关系}{58}
\contentsline {section}{\numberline {6.15}CD Algorithm是如何对原来的分布$p$ 进行优化的}{58}
\contentsline {chapter}{\numberline {第七章\hspace {0.3em}}卷积神经网络CNN}{61}
\contentsline {section}{\numberline {7.1}卷积}{61}
\contentsline {subsection}{\numberline {7.1.1}一维场合}{61}
\contentsline {subsection}{\numberline {7.1.2}二维场合}{62}
\contentsline {section}{\numberline {7.2}卷积层：用卷积代替全链接}{62}
\contentsline {section}{\numberline {7.3}子采样层：池化}{65}
\contentsline {section}{\numberline {7.4}CNN示例：LeNet-5}{66}
\contentsline {section}{\numberline {7.5}梯度计算}{68}
\contentsline {subsection}{\numberline {7.5.1}卷积层的梯度}{68}
\contentsline {subsection}{\numberline {7.5.2}子采样层的梯度}{69}
\contentsline {section}{\numberline {7.6}一个强大的CNN框架：CAFFE}{70}
\contentsline {subsection}{\numberline {7.6.1}Caffe的特点}{70}
\contentsline {subsubsection}{Caffe相对与其他DL框架的优点和缺点}{70}
\contentsline {subsubsection}{Caffe代码层次}{70}
\contentsline {subsection}{\numberline {7.6.2}更进一步的特点}{71}
\contentsline {subsubsection}{Blob}{71}
\contentsline {subsubsection}{Layer}{71}
\contentsline {subsubsection}{Net}{73}
\contentsline {subsubsection}{Solver}{74}
\contentsline {section}{\numberline {7.7}一些关于CNN的技巧}{74}
\contentsline {subsection}{\numberline {7.7.1}Data Augmentation}{74}
\contentsline {subsection}{\numberline {7.7.2}Pre-Processing}{75}
\contentsline {subsection}{\numberline {7.7.3}Initializations}{77}
\contentsline {subsection}{\numberline {7.7.4}During Training}{79}
\contentsline {subsection}{\numberline {7.7.5}Activation Functions}{80}
\contentsline {subsection}{\numberline {7.7.6}Regularizations}{80}
\contentsline {subsection}{\numberline {7.7.7}Insights from Figures}{80}
\contentsline {subsection}{\numberline {7.7.8}Ensemble}{80}
\contentsline {subsection}{\numberline {7.7.9}Miscellaneous}{80}
\contentsline {section}{\numberline {7.8}一些经典论文基于CAFFE的实验重现}{80}
\contentsline {subsection}{\numberline {7.8.1}A Neural Algorithm of Artistic Style}{80}
\contentsline {section}{\numberline {7.9}进一步的阅读和总结}{81}
\contentsline {chapter}{\numberline {第八章\hspace {0.3em}}递归神经网络RNN}{83}
\contentsline {section}{\numberline {8.1}简单的递归网络}{84}
\contentsline {subsection}{\numberline {8.1.1}梯度}{84}
\contentsline {subsection}{\numberline {8.1.2}改进方案}{86}
\contentsline {section}{\numberline {8.2}长短时记忆神经网络：LSTM}{87}
\contentsline {section}{\numberline {8.3}门限循环单元：GRU}{88}
\contentsline {section}{\numberline {8.4}一个强大的RNN框架：DeepNet}{89}
\contentsline {section}{\numberline {8.5}一些经典论文基于DeepNet的实验重现}{89}
\contentsline {section}{\numberline {8.6}进一步的阅读和总结}{89}
\contentsline {chapter}{Appendices}{97}
\contentsline {chapter}{\numberline {第九章\hspace {0.3em}}学习理论的统计机理}{97}
\contentsline {section}{\numberline {9.A}一些约定}{97}
\contentsline {subsection}{\numberline {9.A.1}Annealed Analysis of Gibbs Learning}{97}
\contentsline {subsection}{\numberline {9.A.2}The Annealed Approximation in Statistical Mechanics}{103}
\contentsline {section}{\numberline {9.B}The Gardner Analysis}{104}
\contentsline {section}{\numberline {9.C}Learning by Minimizing Cost Functions}{104}
\contentsline {section}{\numberline {9.D}Noisy Teachers}{104}
\contentsline {section}{\numberline {9.E}Variations of Preceptron Learning}{104}
