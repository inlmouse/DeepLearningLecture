\contentsline {chapter}{\numberline {第一章\hspace {0.3em}}序论}{7}
\contentsline {section}{\numberline {1.1}进一步的阅读和总结}{9}
\contentsline {chapter}{\numberline {第二章\hspace {0.3em}}数学准备知识}{11}
\contentsline {section}{\numberline {2.1}矢量分析}{11}
\contentsline {subsection}{\numberline {2.1.1}矢量的模}{11}
\contentsline {subsection}{\numberline {2.1.2}矢量的范数}{11}
\contentsline {section}{\numberline {2.2}矩阵及其基本运算}{12}
\contentsline {subsection}{\numberline {2.2.1}常见的矩阵}{12}
\contentsline {subsection}{\numberline {2.2.2}矩阵的范数}{12}
\contentsline {section}{\numberline {2.3}导数}{13}
\contentsline {subsection}{\numberline {2.3.1}常见的向量导数}{14}
\contentsline {subsection}{\numberline {2.3.2}导数法则}{14}
\contentsline {section}{\numberline {2.4}常用函数}{15}
\contentsline {subsection}{\numberline {2.4.1}logistic/sigmoid函数}{16}
\contentsline {subsection}{\numberline {2.4.2}softmax函数}{16}
\contentsline {subsection}{\numberline {2.4.3}Rectifier函数(ReLU)}{17}
\contentsline {section}{\numberline {2.5}一些练习}{18}
\contentsline {section}{\numberline {2.6}进一步的阅读和总结}{18}
\contentsline {chapter}{\numberline {第三章\hspace {0.3em}}机器学习概述}{19}
\contentsline {section}{\numberline {3.1}机器学习概述}{19}
\contentsline {subsection}{\numberline {3.1.1}损失函数}{21}
\contentsline {subsection}{\numberline {3.1.2}补充问题：机器学习与信息论的关系}{22}
\contentsline {subsection}{\numberline {3.1.3}机器学习算法的类型}{25}
\contentsline {subsection}{\numberline {3.1.4}机器学习中的一些基本概念}{26}
\contentsline {subsection}{\numberline {3.1.5}参数学习方法}{28}
\contentsline {section}{\numberline {3.2}线性回归}{30}
\contentsline {section}{\numberline {3.3}线性分类}{31}
\contentsline {subsection}{\numberline {3.3.1}二类分类}{31}
\contentsline {subsection}{\numberline {3.3.2}多类线性分类}{31}
\contentsline {section}{\numberline {3.4}评价方法}{31}
\contentsline {section}{\numberline {3.5}进一步的阅读和总结}{31}
\contentsline {chapter}{\numberline {第四章\hspace {0.3em}}感知器}{33}
\contentsline {section}{\numberline {4.1}二类感知器}{33}
\contentsline {subsection}{\numberline {4.1.1}感知器学习算法}{33}
\contentsline {subsection}{\numberline {4.1.2}线性感知器收敛性证明}{33}
\contentsline {section}{\numberline {4.2}多类感知器}{33}
\contentsline {subsection}{\numberline {4.2.1}多类感知器收敛性证明}{33}
\contentsline {section}{\numberline {4.3}投票感知器}{33}
\contentsline {section}{\numberline {4.4}进一步的阅读和总结}{33}
\contentsline {chapter}{\numberline {第五章\hspace {0.3em}}人工神经网络}{35}
\contentsline {section}{\numberline {5.1}神经元}{36}
\contentsline {subsection}{\numberline {5.1.1}激活函数}{36}
\contentsline {subsection}{\numberline {5.1.2}激活函数的表达能力}{37}
\contentsline {section}{\numberline {5.2}前馈神经网络}{41}
\contentsline {subsection}{\numberline {5.2.1}前馈计算}{41}
\contentsline {section}{\numberline {5.3}反向传播算法}{41}
\contentsline {section}{\numberline {5.4}梯度消失问题}{41}
\contentsline {section}{\numberline {5.5}训练方法}{41}
\contentsline {section}{\numberline {5.6}一些经验}{41}
\contentsline {section}{\numberline {5.7}进一步的阅读和总结}{41}
\contentsline {chapter}{\numberline {第六章\hspace {0.3em}}受限波尔兹曼机RBM}{43}
\contentsline {section}{\numberline {6.1}Roadmap}{43}
\contentsline {section}{\numberline {6.2}Notations}{43}
\contentsline {section}{\numberline {6.3}Energy-Based Models}{44}
\contentsline {section}{\numberline {6.4}An Simple Example of Energy-Based Models}{45}
\contentsline {section}{\numberline {6.5}Introducing Hidden Variables}{45}
\contentsline {section}{\numberline {6.6}Gradient Learning of Energy-based Models}{47}
\contentsline {section}{\numberline {6.7}Boltzmann Machines}{48}
\contentsline {section}{\numberline {6.8}Gradient Learning of Boltzmann Machines}{48}
\contentsline {section}{\numberline {6.9}Gibbs Sampling for Conditional Probability}{49}
\contentsline {section}{\numberline {6.10}Gibbs Sampling for Boltzmann Machines}{49}
\contentsline {section}{\numberline {6.11}Restricted Boltzmann Machines}{50}
\contentsline {section}{\numberline {6.12}Gibbs Sampling for Restricted Boltzmann Machines}{50}
\contentsline {section}{\numberline {6.13}Contrastive Divergence}{51}
\contentsline {section}{\numberline {6.14}Gibbs Sampling和Markov Chain以及MCMC的关系}{54}
\contentsline {section}{\numberline {6.15}CD Algorithm是如何对原来的分布$p$进行优化的}{54}
\contentsline {chapter}{\numberline {第七章\hspace {0.3em}}卷积神经网络CNN}{57}
\contentsline {section}{\numberline {7.1}卷积}{57}
\contentsline {subsection}{\numberline {7.1.1}一维场合}{57}
\contentsline {subsection}{\numberline {7.1.2}二维场合}{58}
\contentsline {section}{\numberline {7.2}卷积层：用卷积代替全链接}{58}
\contentsline {section}{\numberline {7.3}子采样层：池化}{61}
\contentsline {section}{\numberline {7.4}CNN示例：LeNet-5}{62}
\contentsline {section}{\numberline {7.5}梯度计算}{64}
\contentsline {subsection}{\numberline {7.5.1}卷积层的梯度}{64}
\contentsline {subsection}{\numberline {7.5.2}子采样层的梯度}{65}
\contentsline {section}{\numberline {7.6}一个强大的CNN框架：CAFFE}{66}
\contentsline {subsection}{\numberline {7.6.1}Caffe的特点}{66}
\contentsline {subsubsection}{Caffe相对与其他DL框架的优点和缺点}{66}
\contentsline {subsubsection}{Caffe代码层次}{66}
\contentsline {subsection}{\numberline {7.6.2}更进一步的特点}{67}
\contentsline {subsubsection}{Blob}{67}
\contentsline {subsubsection}{Layer}{67}
\contentsline {subsubsection}{Net}{69}
\contentsline {subsubsection}{Solver}{70}
\contentsline {section}{\numberline {7.7}一些关于CNN的技巧}{70}
\contentsline {subsection}{\numberline {7.7.1}Data Augmentation}{70}
\contentsline {subsection}{\numberline {7.7.2}Pre-Processing}{71}
\contentsline {subsection}{\numberline {7.7.3}Initializations}{73}
\contentsline {subsection}{\numberline {7.7.4}During Training}{75}
\contentsline {subsection}{\numberline {7.7.5}Activation Functions}{76}
\contentsline {subsection}{\numberline {7.7.6}Regularizations}{76}
\contentsline {subsection}{\numberline {7.7.7}Insights from Figures}{76}
\contentsline {subsection}{\numberline {7.7.8}Ensemble}{76}
\contentsline {subsection}{\numberline {7.7.9}Miscellaneous}{76}
\contentsline {section}{\numberline {7.8}一些经典论文基于CAFFE的实验重现}{76}
\contentsline {subsection}{\numberline {7.8.1}A Neural Algorithm of Artistic Style}{76}
\contentsline {section}{\numberline {7.9}进一步的阅读和总结}{77}
\contentsline {chapter}{\numberline {第八章\hspace {0.3em}}递归神经网络RNN}{79}
\contentsline {section}{\numberline {8.1}简单的递归网络}{80}
\contentsline {subsection}{\numberline {8.1.1}梯度}{80}
\contentsline {subsection}{\numberline {8.1.2}改进方案}{82}
\contentsline {section}{\numberline {8.2}长短时记忆神经网络：LSTM}{83}
\contentsline {section}{\numberline {8.3}门限循环单元：GRU}{84}
\contentsline {section}{\numberline {8.4}一个强大的RNN框架：DeepNet}{85}
\contentsline {section}{\numberline {8.5}一些经典论文基于DeepNet的实验重现}{85}
\contentsline {section}{\numberline {8.6}进一步的阅读和总结}{85}
