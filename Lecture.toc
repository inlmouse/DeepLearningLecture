\contentsline {chapter}{\numberline {第一章\hspace {0.3em}}序论}{7}
\contentsline {section}{\numberline {1.1}进一步的阅读和总结}{9}
\contentsline {chapter}{\numberline {第二章\hspace {0.3em}}数学准备知识}{11}
\contentsline {section}{\numberline {2.1}矢量分析}{11}
\contentsline {subsection}{\numberline {2.1.1}矢量的模}{11}
\contentsline {subsection}{\numberline {2.1.2}矢量的范数}{11}
\contentsline {section}{\numberline {2.2}矩阵及其基本运算}{12}
\contentsline {subsection}{\numberline {2.2.1}常见的矩阵}{12}
\contentsline {subsection}{\numberline {2.2.2}矩阵的范数}{12}
\contentsline {section}{\numberline {2.3}导数}{13}
\contentsline {subsection}{\numberline {2.3.1}常见的向量导数}{14}
\contentsline {subsection}{\numberline {2.3.2}导数法则}{14}
\contentsline {section}{\numberline {2.4}常用函数}{15}
\contentsline {subsection}{\numberline {2.4.1}logistic/sigmoid函数}{16}
\contentsline {subsection}{\numberline {2.4.2}softmax函数}{16}
\contentsline {subsection}{\numberline {2.4.3}Rectifier函数(ReLU)}{17}
\contentsline {section}{\numberline {2.5}一些练习}{18}
\contentsline {section}{\numberline {2.6}进一步的阅读和总结}{18}
\contentsline {chapter}{\numberline {第三章\hspace {0.3em}}机器学习概述}{19}
\contentsline {section}{\numberline {3.1}机器学习概述}{19}
\contentsline {subsection}{\numberline {3.1.1}补充问题：正则化}{21}
\contentsline {subsection}{\numberline {3.1.2}损失函数}{24}
\contentsline {subsection}{\numberline {3.1.3}补充问题：机器学习与信息论的关系}{26}
\contentsline {subsection}{\numberline {3.1.4}机器学习算法的类型}{29}
\contentsline {subsection}{\numberline {3.1.5}机器学习中的一些基本概念}{30}
\contentsline {subsection}{\numberline {3.1.6}参数学习方法}{31}
\contentsline {section}{\numberline {3.2}线性回归}{34}
\contentsline {section}{\numberline {3.3}线性分类}{34}
\contentsline {subsection}{\numberline {3.3.1}二类分类}{34}
\contentsline {subsection}{\numberline {3.3.2}多类线性分类}{34}
\contentsline {section}{\numberline {3.4}评价方法}{34}
\contentsline {section}{\numberline {3.5}进一步的阅读和总结}{34}
\contentsline {chapter}{\numberline {第四章\hspace {0.3em}}感知器}{35}
\contentsline {section}{\numberline {4.1}二类感知器}{35}
\contentsline {subsection}{\numberline {4.1.1}感知器学习算法}{35}
\contentsline {subsection}{\numberline {4.1.2}线性感知器收敛性证明}{35}
\contentsline {section}{\numberline {4.2}多类感知器}{35}
\contentsline {subsection}{\numberline {4.2.1}多类感知器收敛性证明}{35}
\contentsline {section}{\numberline {4.3}投票感知器}{35}
\contentsline {section}{\numberline {4.4}进一步的阅读和总结}{35}
\contentsline {chapter}{\numberline {第五章\hspace {0.3em}}人工神经网络}{37}
\contentsline {section}{\numberline {5.1}神经元}{38}
\contentsline {subsection}{\numberline {5.1.1}激活函数}{38}
\contentsline {subsection}{\numberline {5.1.2}激活函数的表达能力}{39}
\contentsline {section}{\numberline {5.2}前馈神经网络}{43}
\contentsline {subsection}{\numberline {5.2.1}前馈计算}{43}
\contentsline {section}{\numberline {5.3}反向传播算法}{43}
\contentsline {section}{\numberline {5.4}梯度消失问题}{43}
\contentsline {section}{\numberline {5.5}训练方法}{43}
\contentsline {section}{\numberline {5.6}一些经验}{43}
\contentsline {section}{\numberline {5.7}进一步的阅读和总结}{43}
\contentsline {chapter}{\numberline {第六章\hspace {0.3em}}受限波尔兹曼机RBM}{45}
\contentsline {section}{\numberline {6.1}Roadmap}{45}
\contentsline {section}{\numberline {6.2}Notations}{45}
\contentsline {section}{\numberline {6.3}Energy-Based Models}{46}
\contentsline {section}{\numberline {6.4}An Simple Example of Energy-Based Models}{47}
\contentsline {section}{\numberline {6.5}Introducing Hidden Variables}{47}
\contentsline {section}{\numberline {6.6}Gradient Learning of Energy-based Models}{49}
\contentsline {section}{\numberline {6.7}Boltzmann Machines}{50}
\contentsline {section}{\numberline {6.8}Gradient Learning of Boltzmann Machines}{50}
\contentsline {section}{\numberline {6.9}Gibbs Sampling for Conditional Probability}{51}
\contentsline {section}{\numberline {6.10}Gibbs Sampling for Boltzmann Machines}{51}
\contentsline {section}{\numberline {6.11}Restricted Boltzmann Machines}{52}
\contentsline {section}{\numberline {6.12}Gibbs Sampling for Restricted Boltzmann Machines}{52}
\contentsline {section}{\numberline {6.13}Contrastive Divergence}{53}
\contentsline {section}{\numberline {6.14}Gibbs Sampling和Markov Chain以及MCMC的关系}{56}
\contentsline {section}{\numberline {6.15}CD Algorithm是如何对原来的分布$p$ 进行优化的}{56}
\contentsline {chapter}{\numberline {第七章\hspace {0.3em}}卷积神经网络CNN}{59}
\contentsline {section}{\numberline {7.1}卷积}{59}
\contentsline {subsection}{\numberline {7.1.1}一维场合}{59}
\contentsline {subsection}{\numberline {7.1.2}二维场合}{60}
\contentsline {section}{\numberline {7.2}卷积层：用卷积代替全链接}{60}
\contentsline {section}{\numberline {7.3}子采样层：池化}{63}
\contentsline {section}{\numberline {7.4}CNN示例：LeNet-5}{64}
\contentsline {section}{\numberline {7.5}梯度计算}{66}
\contentsline {subsection}{\numberline {7.5.1}卷积层的梯度}{66}
\contentsline {subsection}{\numberline {7.5.2}子采样层的梯度}{67}
\contentsline {section}{\numberline {7.6}一个强大的CNN框架：CAFFE}{68}
\contentsline {subsection}{\numberline {7.6.1}Caffe的特点}{68}
\contentsline {subsubsection}{Caffe相对与其他DL框架的优点和缺点}{68}
\contentsline {subsubsection}{Caffe代码层次}{68}
\contentsline {subsection}{\numberline {7.6.2}更进一步的特点}{69}
\contentsline {subsubsection}{Blob}{69}
\contentsline {subsubsection}{Layer}{69}
\contentsline {subsubsection}{Net}{71}
\contentsline {subsubsection}{Solver}{72}
\contentsline {section}{\numberline {7.7}一些关于CNN的技巧}{72}
\contentsline {subsection}{\numberline {7.7.1}Data Augmentation}{72}
\contentsline {subsection}{\numberline {7.7.2}Pre-Processing}{73}
\contentsline {subsection}{\numberline {7.7.3}Initializations}{75}
\contentsline {subsection}{\numberline {7.7.4}During Training}{77}
\contentsline {subsection}{\numberline {7.7.5}Activation Functions}{78}
\contentsline {subsection}{\numberline {7.7.6}Regularizations}{78}
\contentsline {subsection}{\numberline {7.7.7}Insights from Figures}{78}
\contentsline {subsection}{\numberline {7.7.8}Ensemble}{78}
\contentsline {subsection}{\numberline {7.7.9}Miscellaneous}{78}
\contentsline {section}{\numberline {7.8}一些经典论文基于CAFFE的实验重现}{78}
\contentsline {subsection}{\numberline {7.8.1}A Neural Algorithm of Artistic Style}{78}
\contentsline {section}{\numberline {7.9}进一步的阅读和总结}{79}
\contentsline {chapter}{\numberline {第八章\hspace {0.3em}}递归神经网络RNN}{81}
\contentsline {section}{\numberline {8.1}简单的递归网络}{82}
\contentsline {subsection}{\numberline {8.1.1}梯度}{82}
\contentsline {subsection}{\numberline {8.1.2}改进方案}{84}
\contentsline {section}{\numberline {8.2}长短时记忆神经网络：LSTM}{85}
\contentsline {section}{\numberline {8.3}门限循环单元：GRU}{86}
\contentsline {section}{\numberline {8.4}一个强大的RNN框架：DeepNet}{87}
\contentsline {section}{\numberline {8.5}一些经典论文基于DeepNet的实验重现}{87}
\contentsline {section}{\numberline {8.6}进一步的阅读和总结}{87}
