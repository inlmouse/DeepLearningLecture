\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {第一章\hspace  {0.3em}}序论}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\citation{rosenblatt1958perceptron}
\citation{rumelhart1988learning}
\citation{hinton2006reducing}
\citation{hinton2012deep}
\citation{krizhevsky2012imagenet}
\citation{Goodfellow-et-al-2015-Book}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}进一步的阅读和总结}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第二章\hspace  {0.3em}}数学准备知识}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}矢量分析}{11}}
\newlabel{2.1}{{2.1}{11}}
\newlabel{2.2}{{2.2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}矢量的模}{11}}
\newlabel{2.3}{{2.3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}矢量的范数}{11}}
\newlabel{2.4}{{2.4}{12}}
\newlabel{2.5}{{2.5}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}矩阵及其基本运算}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}常见的矩阵}{12}}
\newlabel{2.6}{{2.6}{12}}
\newlabel{2.7}{{2.7}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}矩阵的范数}{12}}
\newlabel{compatibility}{{2.8}{12}}
\newlabel{2.8}{{2.9}{12}}
\newlabel{UnitaryInvariance}{{2.10}{13}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}导数}{13}}
\newlabel{div}{{2.11}{13}}
\newlabel{2.9}{{2.12}{13}}
\newlabel{2.10}{{2.13}{14}}
\newlabel{divmat}{{2.14}{14}}
\newlabel{innerdivmat}{{2.15}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}常见的向量导数}{14}}
\newlabel{ex1}{{2.16}{14}}
\newlabel{ex2}{{2.17}{14}}
\newlabel{ex3}{{2.18}{14}}
\newlabel{2.11}{{2.19}{14}}
\newlabel{2.12}{{2.20}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}导数法则}{14}}
\newlabel{2.13}{{2.21}{15}}
\newlabel{2.14}{{2.22}{15}}
\newlabel{2.15}{{2.23}{15}}
\newlabel{2.16}{{2.24}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}常用函数}{15}}
\newlabel{2.17}{{2.25}{15}}
\newlabel{2.18}{{2.26}{15}}
\newlabel{2.19}{{2.27}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}logistic/sigmoid函数}{16}}
\newlabel{2.20}{{2.28}{16}}
\newlabel{2.21}{{2.29}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}softmax函数}{16}}
\newlabel{2.22}{{2.30}{16}}
\newlabel{2.23}{{2.31}{16}}
\newlabel{2.24}{{2.32}{16}}
\newlabel{2.27}{{2.35}{17}}
\newlabel{2.30}{{2.38}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.3}Rectifier函数(ReLU)}{17}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}一些练习}{18}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}进一步的阅读和总结}{18}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第三章\hspace  {0.3em}}机器学习概述}{19}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}机器学习概述}{19}}
\newlabel{3.1}{{3.1}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 机器学习系统示意图}}{19}}
\newlabel{fig:3.1}{{3.1}{19}}
\citation{mitchell1998introduction}
\newlabel{3.2}{{3.2}{20}}
\newlabel{3.3}{{3.3}{20}}
\newlabel{3.4}{{3.4}{20}}
\newlabel{3.5}{{3.5}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}损失函数}{21}}
\newlabel{3.7}{{3.7}{21}}
\newlabel{3.8}{{3.8}{21}}
\newlabel{3.9}{{3.9}{21}}
\citation{principe2000information}
\newlabel{3.10}{{3.10}{22}}
\newlabel{3.11}{{3.11}{22}}
\newlabel{3.12}{{3.12}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}补充问题：机器学习与信息论的关系}{22}}
\citation{mackay2003information}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Some information formulas and their properties as learning measures}}{23}}
\newlabel{fig:3.2}{{3.2}{23}}
\citation{hu2015information}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The relationship among some measures}}{24}}
\newlabel{fig:3.3}{{3.3}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The relationship among $E,Rej,A,CR$}}{24}}
\newlabel{fig:3.4}{{3.4}{24}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Example}}{25}}
\newlabel{fig:3.5}{{3.5}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}机器学习算法的类型}{25}}
\newlabel{3.13}{{3.13}{25}}
\newlabel{3.14}{{3.14}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}机器学习中的一些基本概念}{26}}
\newlabel{3.15}{{3.15}{27}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}参数学习方法}{28}}
\newlabel{3.16}{{3.16}{28}}
\newlabel{3.17}{{3.17}{28}}
\newlabel{3.19}{{3.19}{28}}
\citation{rumelhart1988learning}
\citation{duchi2011adaptive}
\newlabel{3.20}{{3.21}{29}}
\newlabel{3.21}{{3.22}{29}}
\citation{zeiler2012adadelta}
\newlabel{3.22}{{3.23}{30}}
\newlabel{3.23}{{3.24}{30}}
\newlabel{3.24}{{3.25}{30}}
\newlabel{3.25}{{3.26}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}线性回归}{30}}
\newlabel{3.26}{{3.27}{30}}
\newlabel{3.27}{{3.28}{30}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}线性分类}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}二类分类}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}多类线性分类}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}评价方法}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}进一步的阅读和总结}{31}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第四章\hspace  {0.3em}}感知器}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}二类感知器}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}感知器学习算法}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}线性感知器收敛性证明}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}多类感知器}{33}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}多类感知器收敛性证明}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}投票感知器}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}进一步的阅读和总结}{33}}
\citation{bishop2006pattern}
\@writefile{toc}{\contentsline {chapter}{\numberline {第五章\hspace  {0.3em}}人工神经网络}{35}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}神经元}{36}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}激活函数}{36}}
\citation{glorot2010understanding}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Neuron}}{37}}
\newlabel{fig:5.1}{{5.1}{37}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.2}激活函数的表达能力}{37}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces Activation Function}}{38}}
\newlabel{fig:5.2}{{5.2}{38}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces $s$-Volume}}{41}}
\newlabel{fig:5.3}{{5.3}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}前馈神经网络}{41}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}前馈计算}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}反向传播算法}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}梯度消失问题}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}训练方法}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}一些经验}{41}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}进一步的阅读和总结}{41}}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {chapter}{\numberline {第六章\hspace  {0.3em}}受限波尔兹曼机RBM}{43}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Roadmap}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Notations}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Energy-Based Models}{44}}
\newlabel{add1.1}{{6.1}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An Simple Example of Energy-Based Models}}{45}}
\newlabel{fig:add1}{{6.1}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}An Simple Example of Energy-Based Models}{45}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces $Energy(a,b)$ and the probability for each configuration}}{45}}
\newlabel{tab:Energy}{{6.1}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Introducing Hidden Variables}{45}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Model}}{46}}
\newlabel{fig:add2}{{6.2}{46}}
\newlabel{add1.2}{{6.2}{46}}
\newlabel{add1.3}{{6.3}{46}}
\newlabel{add1.4}{{6.4}{46}}
\newlabel{add1.5}{{6.5}{46}}
\newlabel{add1.6}{{6.6}{46}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Gradient Learning of Energy-based Models}}{47}}
\newlabel{fig:add3}{{6.3}{47}}
\newlabel{add1.7}{{6.7}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Gradient Learning of Energy-based Models}{47}}
\newlabel{add1.8}{{6.8}{47}}
\@writefile{toc}{\contentsline {section}{\numberline {6.7}Boltzmann Machines}{48}}
\newlabel{BME}{{6.9}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {6.8}Gradient Learning of Boltzmann Machines}{48}}
\newlabel{LLG}{{6.10}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {6.9}Gibbs Sampling for Conditional Probability}{49}}
\@writefile{toc}{\contentsline {section}{\numberline {6.10}Gibbs Sampling for Boltzmann Machines}{49}}
\citation{hinton2002training}
\citation{welling2007product}
\@writefile{toc}{\contentsline {section}{\numberline {6.11}Restricted Boltzmann Machines}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {6.12}Gibbs Sampling for Restricted Boltzmann Machines}{50}}
\@writefile{toc}{\contentsline {section}{\numberline {6.13}Contrastive Divergence}{51}}
\newlabel{CDk}{{6.11}{52}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces k-step contrastive divergence}}{53}}
\@writefile{toc}{\contentsline {section}{\numberline {6.14}Gibbs Sampling和Markov Chain以及MCMC的关系}{54}}
\@writefile{toc}{\contentsline {section}{\numberline {6.15}CD Algorithm是如何对原来的分布$p$进行优化的}{54}}
\citation{hubel1968receptive}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {chapter}{\numberline {第七章\hspace  {0.3em}}卷积神经网络CNN}{57}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}卷积}{57}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}一维场合}{57}}
\newlabel{6.1}{{7.1}{57}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Full Connection Layer and Convolutional Layer}}{58}}
\newlabel{fig:6.1}{{7.1}{58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}二维场合}{58}}
\newlabel{6.2}{{7.2}{58}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}卷积层：用卷积代替全链接}{58}}
\newlabel{6.2}{{7.3}{59}}
\newlabel{6.5}{{7.5}{59}}
\newlabel{6.6}{{7.6}{59}}
\newlabel{6.7}{{7.7}{59}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces The mapping relationship of 2-D convolutional layer}}{60}}
\newlabel{fig:6.2}{{7.2}{60}}
\newlabel{6.8}{{7.8}{60}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces 2-D convolutional layer}}{61}}
\newlabel{fig:6.3}{{7.3}{61}}
\newlabel{6.9}{{7.9}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}子采样层：池化}{61}}
\newlabel{6.10}{{7.10}{61}}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Net Structure of LeNet-5}}{62}}
\newlabel{fig:6.4}{{7.4}{62}}
\newlabel{6.12}{{7.12}{62}}
\newlabel{6.14}{{7.14}{62}}
\newlabel{6.15}{{7.15}{62}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}CNN示例：LeNet-5}{62}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Connection table of LeNet-5's C3 layer}}{63}}
\newlabel{fig:6.5}{{7.5}{63}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}梯度计算}{64}}
\newlabel{6.16}{{7.16}{64}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}卷积层的梯度}{64}}
\newlabel{6.18}{{7.18}{64}}
\newlabel{6.22}{{7.22}{65}}
\newlabel{6.24}{{7.24}{65}}
\newlabel{6.25}{{7.25}{65}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}子采样层的梯度}{65}}
\newlabel{6.26}{{7.26}{65}}
\newlabel{6.27}{{7.27}{65}}
\newlabel{6.30}{{7.30}{66}}
\newlabel{6.31}{{7.31}{66}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}一个强大的CNN框架：CAFFE}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Caffe的特点}{66}}
\@writefile{toc}{\contentsline {subsubsection}{Caffe相对与其他DL框架的优点和缺点}{66}}
\@writefile{toc}{\contentsline {subsubsection}{Caffe代码层次}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}更进一步的特点}{67}}
\@writefile{toc}{\contentsline {subsubsection}{Blob}{67}}
\@writefile{toc}{\contentsline {subsubsection}{Layer}{67}}
\@writefile{toc}{\contentsline {subsubsection}{Net}{69}}
\@writefile{toc}{\contentsline {subsubsection}{Solver}{70}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}一些关于CNN的技巧}{70}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}Data Augmentation}{70}}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.2}Pre-Processing}{71}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.3}Initializations}{73}}
\citation{he2015delving}
\citation{he2015delving}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.4}During Training}{75}}
\citation{gatys2015neural}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.5}Activation Functions}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.6}Regularizations}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.7}Insights from Figures}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.8}Ensemble}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.9}Miscellaneous}{76}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}一些经典论文基于CAFFE的实验重现}{76}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.8.1}A Neural Algorithm of Artistic Style}{76}}
\@writefile{toc}{\contentsline {section}{\numberline {7.9}进一步的阅读和总结}{77}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Images that combine the content of a photograph with the style of several well-known artworks.}}{78}}
\newlabel{fig:6.6}{{7.6}{78}}
\citation{waibel1989phoneme}
\citation{werbos1990backpropagation}
\citation{bengio1994learning}
\citation{hochreiter1997long}
\citation{hochreiter2001gradient}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {chapter}{\numberline {第八章\hspace  {0.3em}}递归神经网络RNN}{79}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{loa}{\addvspace {10\p@ }}
\newlabel{7.1}{{8.1}{79}}
\citation{elman1990finding}
\citation{werbos1990backpropagation}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces RNN}}{80}}
\newlabel{fig:7.1}{{8.1}{80}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}简单的递归网络}{80}}
\newlabel{7.2}{{8.2}{80}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}梯度}{80}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Simple RNN expanded by time}}{81}}
\newlabel{fig:7.2}{{8.2}{81}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces RNN expanded by time}}{81}}
\newlabel{fig:7.3}{{8.3}{81}}
\newlabel{7.3}{{8.3}{81}}
\newlabel{7.5}{{8.5}{81}}
\newlabel{7.6}{{8.6}{81}}
\newlabel{7.8}{{8.8}{82}}
\newlabel{7.9}{{8.9}{82}}
\newlabel{7.10}{{8.10}{82}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}改进方案}{82}}
\newlabel{7.11}{{8.11}{82}}
\citation{hochreiter1997long}
\citation{hochreiter1997long}
\citation{sutskever2014sequence}
\newlabel{7.12}{{8.12}{83}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}长短时记忆神经网络：LSTM}{83}}
\newlabel{7.14}{{8.14}{83}}
\citation{cho2014learning}
\citation{chung2014empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces LSTM Structure Expamle}}{84}}
\newlabel{fig:7.4}{{8.4}{84}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}门限循环单元：GRU}{84}}
\bibstyle{plain}
\bibdata{Lect}
\newlabel{7.20}{{8.20}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}一个强大的RNN框架：DeepNet}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}一些经典论文基于DeepNet的实验重现}{85}}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}进一步的阅读和总结}{85}}
\bibcite{bengio2009learning}{1}
\bibcite{bengio1994learning}{2}
\bibcite{bishop2006pattern}{3}
\bibcite{cho2014learning}{4}
\bibcite{chung2014empirical}{5}
\bibcite{duchi2011adaptive}{6}
\bibcite{elman1990finding}{7}
\bibcite{gatys2015neural}{8}
\bibcite{glorot2010understanding}{9}
\bibcite{Goodfellow-et-al-2015-Book}{10}
\bibcite{he2015delving}{11}
\bibcite{hinton2012deep}{12}
\bibcite{hinton2002training}{13}
\bibcite{hinton2006reducing}{14}
\bibcite{hochreiter2001gradient}{15}
\bibcite{hochreiter1997long}{16}
\bibcite{hu2015information}{17}
\bibcite{hubel1968receptive}{18}
\bibcite{krizhevsky2012imagenet}{19}
\bibcite{lecun1998gradient}{20}
\bibcite{mackay2003information}{21}
\bibcite{mitchell1998introduction}{22}
\bibcite{principe2000information}{23}
\bibcite{rosenblatt1958perceptron}{24}
\bibcite{rumelhart1988learning}{25}
\bibcite{sutskever2014sequence}{26}
\bibcite{waibel1989phoneme}{27}
\bibcite{welling2007product}{28}
\bibcite{werbos1990backpropagation}{29}
\bibcite{zeiler2012adadelta}{30}
