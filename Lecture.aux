\relax 
\@writefile{toc}{\contentsline {chapter}{\numberline {第一章\hspace  {0.3em}}序论}{7}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{rosenblatt1958perceptron}
\citation{rumelhart1988learning}
\citation{hinton2006reducing}
\citation{hinton2012deep}
\citation{krizhevsky2012imagenet}
\citation{Goodfellow-et-al-2015-Book}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}进一步的阅读和总结}{9}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第二章\hspace  {0.3em}}数学准备知识}{11}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}矢量分析}{11}}
\newlabel{2.1}{{2.1}{11}}
\newlabel{2.2}{{2.2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}矢量的模}{11}}
\newlabel{2.3}{{2.3}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}矢量的范数}{11}}
\newlabel{2.4}{{2.4}{12}}
\newlabel{2.5}{{2.5}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}矩阵及其基本运算}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}常见的矩阵}{12}}
\newlabel{2.6}{{2.6}{12}}
\newlabel{2.7}{{2.7}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}矩阵的范数}{12}}
\newlabel{2.8}{{2.8}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}导数}{13}}
\newlabel{2.9}{{2.9}{13}}
\newlabel{2.10}{{2.10}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}常见的向量导数}{13}}
\newlabel{2.11}{{2.11}{13}}
\newlabel{2.12}{{2.12}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}导数法则}{13}}
\newlabel{2.13}{{2.13}{13}}
\newlabel{2.14}{{2.14}{13}}
\newlabel{2.15}{{2.15}{14}}
\newlabel{2.16}{{2.16}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}常用函数}{14}}
\newlabel{2.17}{{2.17}{14}}
\newlabel{2.18}{{2.18}{14}}
\newlabel{2.19}{{2.19}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.1}logistic函数}{14}}
\newlabel{2.20}{{2.20}{14}}
\newlabel{2.21}{{2.21}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4.2}softmax函数}{15}}
\newlabel{2.22}{{2.22}{15}}
\newlabel{2.23}{{2.23}{15}}
\newlabel{2.24}{{2.24}{15}}
\newlabel{2.27}{{2.27}{15}}
\newlabel{2.30}{{2.30}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {2.5}一些练习}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {2.6}进一步的阅读和总结}{16}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第三章\hspace  {0.3em}}机器学习概述}{17}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}机器学习概述}{17}}
\newlabel{3.1}{{3.1}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces 机器学习系统示意图}}{17}}
\newlabel{fig:3.1}{{3.1}{17}}
\citation{mitchell1998introduction}
\newlabel{3.2}{{3.2}{18}}
\newlabel{3.3}{{3.3}{18}}
\newlabel{3.4}{{3.4}{18}}
\newlabel{3.5}{{3.5}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.1}损失函数}{19}}
\newlabel{3.7}{{3.7}{19}}
\newlabel{3.8}{{3.8}{19}}
\newlabel{3.9}{{3.9}{19}}
\newlabel{3.10}{{3.10}{19}}
\citation{principe2000information}
\newlabel{3.11}{{3.11}{20}}
\newlabel{3.12}{{3.12}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.2}补充问题：机器学习与信息论的关系}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Some information formulas and their properties as learning measures}}{20}}
\newlabel{fig:3.2}{{3.2}{20}}
\citation{mackay2003information}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces The relationship among some measures}}{21}}
\newlabel{fig:3.3}{{3.3}{21}}
\citation{hu2015information}
\@writefile{lof}{\contentsline {figure}{\numberline {3.4}{\ignorespaces The relationship among $E,Rej,A,CR$}}{22}}
\newlabel{fig:3.4}{{3.4}{22}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.5}{\ignorespaces Example}}{23}}
\newlabel{fig:3.5}{{3.5}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.3}机器学习算法的类型}{23}}
\newlabel{3.13}{{3.13}{23}}
\newlabel{3.14}{{3.14}{23}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.4}机器学习中的一些基本概念}{24}}
\newlabel{3.15}{{3.15}{25}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1.5}参数学习方法}{25}}
\newlabel{3.16}{{3.16}{26}}
\newlabel{3.17}{{3.17}{26}}
\newlabel{3.19}{{3.19}{26}}
\newlabel{3.20}{{3.21}{26}}
\citation{rumelhart1988learning}
\citation{duchi2011adaptive}
\citation{zeiler2012adadelta}
\newlabel{3.21}{{3.22}{27}}
\newlabel{3.22}{{3.23}{27}}
\newlabel{3.23}{{3.24}{27}}
\newlabel{3.24}{{3.25}{28}}
\newlabel{3.25}{{3.26}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}线性回归}{28}}
\newlabel{3.26}{{3.27}{28}}
\newlabel{3.27}{{3.28}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}线性分类}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.1}二类分类}{28}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3.2}多类线性分类}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}评价方法}{28}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}进一步的阅读和总结}{28}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第四章\hspace  {0.3em}}感知器}{29}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}二类感知器}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.1}感知器学习算法}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1.2}线性感知器收敛性证明}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}多类感知器}{29}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2.1}多类感知器收敛性证明}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}投票感知器}{29}}
\@writefile{toc}{\contentsline {section}{\numberline {4.4}进一步的阅读和总结}{29}}
\@writefile{toc}{\contentsline {chapter}{\numberline {第五章\hspace  {0.3em}}人工神经网络}{31}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}神经元}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}激活函数}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}前馈神经网络}{31}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2.1}前馈计算}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}反向传播算法}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}梯度消失问题}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}训练方法}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.6}一些经验}{31}}
\@writefile{toc}{\contentsline {section}{\numberline {5.7}进一步的阅读和总结}{31}}
\citation{bengio2009learning}
\@writefile{toc}{\contentsline {chapter}{\numberline {第六章\hspace  {0.3em}}受限波尔兹曼机RBM}{33}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Roadmap}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Notations}{33}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Energy-Based Models}{34}}
\newlabel{add1.1}{{6.1}{34}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces An Simple Example of Energy-Based Models}}{35}}
\newlabel{fig:add1}{{6.1}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}An Simple Example of Energy-Based Models}{35}}
\@writefile{lot}{\contentsline {table}{\numberline {6.1}{\ignorespaces $Energy(a,b)$ and the probability for each configuration}}{35}}
\newlabel{tab:Energy}{{6.1}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {6.5}Introducing Hidden Variables}{35}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Model}}{36}}
\newlabel{fig:add2}{{6.2}{36}}
\newlabel{add1.2}{{6.2}{36}}
\newlabel{add1.3}{{6.3}{36}}
\newlabel{add1.4}{{6.4}{36}}
\newlabel{add1.5}{{6.5}{36}}
\newlabel{add1.6}{{6.6}{36}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Gradient Learning of Energy-based Models}}{37}}
\newlabel{fig:add3}{{6.3}{37}}
\newlabel{add1.7}{{6.7}{37}}
\@writefile{toc}{\contentsline {section}{\numberline {6.6}Gradient Learning of Energy-based Models}{37}}
\newlabel{add1.8}{{6.8}{37}}
\citation{hubel1968receptive}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {chapter}{\numberline {第七章\hspace  {0.3em}}卷积神经网络CNN}{39}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}卷积}{39}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}一维场合}{39}}
\newlabel{6.1}{{7.1}{39}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Full Connection Layer and Convolutional Layer}}{40}}
\newlabel{fig:6.1}{{7.1}{40}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.2}二维场合}{40}}
\newlabel{6.2}{{7.2}{40}}
\@writefile{toc}{\contentsline {section}{\numberline {7.2}卷积层：用卷积代替全链接}{40}}
\newlabel{6.2}{{7.3}{41}}
\newlabel{6.5}{{7.5}{41}}
\newlabel{6.6}{{7.6}{41}}
\newlabel{6.7}{{7.7}{41}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces The mapping relationship of 2-D convolutional layer}}{42}}
\newlabel{fig:6.2}{{7.2}{42}}
\newlabel{6.8}{{7.8}{42}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces 2-D convolutional layer}}{43}}
\newlabel{fig:6.3}{{7.3}{43}}
\newlabel{6.9}{{7.9}{43}}
\@writefile{toc}{\contentsline {section}{\numberline {7.3}子采样层：池化}{43}}
\newlabel{6.10}{{7.10}{43}}
\citation{lecun1998gradient}
\@writefile{lof}{\contentsline {figure}{\numberline {7.4}{\ignorespaces Net Structure of LeNet-5}}{44}}
\newlabel{fig:6.4}{{7.4}{44}}
\newlabel{6.12}{{7.12}{44}}
\newlabel{6.14}{{7.14}{44}}
\newlabel{6.15}{{7.15}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {7.4}CNN示例：LeNet-5}{44}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.5}{\ignorespaces Connection table of LeNet-5's C3 layer}}{45}}
\newlabel{fig:6.5}{{7.5}{45}}
\@writefile{toc}{\contentsline {section}{\numberline {7.5}梯度计算}{46}}
\newlabel{6.16}{{7.16}{46}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.1}卷积层的梯度}{46}}
\newlabel{6.18}{{7.18}{46}}
\newlabel{6.22}{{7.22}{47}}
\newlabel{6.24}{{7.24}{47}}
\newlabel{6.25}{{7.25}{47}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.5.2}子采样层的梯度}{47}}
\newlabel{6.26}{{7.26}{47}}
\newlabel{6.27}{{7.27}{47}}
\newlabel{6.30}{{7.30}{48}}
\newlabel{6.31}{{7.31}{48}}
\@writefile{toc}{\contentsline {section}{\numberline {7.6}一个强大的CNN框架：CAFFE}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.1}Caffe的特点}{48}}
\@writefile{toc}{\contentsline {subsubsection}{Caffe相对与其他DL框架的优点和缺点}{48}}
\@writefile{toc}{\contentsline {subsubsection}{Caffe代码层次}{48}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.6.2}更进一步的特点}{49}}
\@writefile{toc}{\contentsline {subsubsection}{Blob}{49}}
\@writefile{toc}{\contentsline {subsubsection}{Layer}{49}}
\@writefile{toc}{\contentsline {subsubsection}{Net}{51}}
\citation{gatys2015neural}
\@writefile{toc}{\contentsline {subsubsection}{Solver}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {7.7}一些经典论文基于CAFFE的实验重现}{52}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.7.1}A Neural Algorithm of Artistic Style}{52}}
\@writefile{toc}{\contentsline {section}{\numberline {7.8}进一步的阅读和总结}{53}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.6}{\ignorespaces Images that combine the content of a photograph with the style of several well-known artworks.}}{54}}
\newlabel{fig:6.6}{{7.6}{54}}
\citation{waibel1989phoneme}
\citation{werbos1990backpropagation}
\citation{bengio1994learning}
\citation{hochreiter1997long}
\citation{hochreiter2001gradient}
\citation{hochreiter1997long}
\@writefile{toc}{\contentsline {chapter}{\numberline {第八章\hspace  {0.3em}}递归神经网络RNN}{55}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{7.1}{{8.1}{55}}
\citation{elman1990finding}
\citation{werbos1990backpropagation}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces RNN}}{56}}
\newlabel{fig:7.1}{{8.1}{56}}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}简单的递归网络}{56}}
\newlabel{7.2}{{8.2}{56}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.1}梯度}{56}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Simple RNN expanded by time}}{57}}
\newlabel{fig:7.2}{{8.2}{57}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces RNN expanded by time}}{57}}
\newlabel{fig:7.3}{{8.3}{57}}
\newlabel{7.3}{{8.3}{57}}
\newlabel{7.5}{{8.5}{57}}
\newlabel{7.6}{{8.6}{57}}
\newlabel{7.8}{{8.8}{58}}
\newlabel{7.9}{{8.9}{58}}
\newlabel{7.10}{{8.10}{58}}
\@writefile{toc}{\contentsline {subsection}{\numberline {8.1.2}改进方案}{58}}
\newlabel{7.11}{{8.11}{58}}
\citation{hochreiter1997long}
\citation{hochreiter1997long}
\citation{sutskever2014sequence}
\newlabel{7.12}{{8.12}{59}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}长短时记忆神经网络：LSTM}{59}}
\newlabel{7.14}{{8.14}{59}}
\citation{cho2014learning}
\citation{chung2014empirical}
\@writefile{lof}{\contentsline {figure}{\numberline {8.4}{\ignorespaces LSTM Structure Expamle}}{60}}
\newlabel{fig:7.4}{{8.4}{60}}
\@writefile{toc}{\contentsline {section}{\numberline {8.3}门限循环单元：GRU}{60}}
\bibstyle{plain}
\bibdata{Lect}
\newlabel{7.20}{{8.20}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {8.4}一个强大的RNN框架：DeepNet}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {8.5}一些经典论文基于DeepNet的实验重现}{61}}
\@writefile{toc}{\contentsline {section}{\numberline {8.6}进一步的阅读和总结}{61}}
\bibcite{bengio2009learning}{1}
\bibcite{bengio1994learning}{2}
\bibcite{cho2014learning}{3}
\bibcite{chung2014empirical}{4}
\bibcite{duchi2011adaptive}{5}
\bibcite{elman1990finding}{6}
\bibcite{gatys2015neural}{7}
\bibcite{Goodfellow-et-al-2015-Book}{8}
\bibcite{hinton2012deep}{9}
\bibcite{hinton2006reducing}{10}
\bibcite{hochreiter2001gradient}{11}
\bibcite{hochreiter1997long}{12}
\bibcite{hu2015information}{13}
\bibcite{hubel1968receptive}{14}
\bibcite{krizhevsky2012imagenet}{15}
\bibcite{lecun1998gradient}{16}
\bibcite{mackay2003information}{17}
\bibcite{mitchell1998introduction}{18}
\bibcite{principe2000information}{19}
\bibcite{rosenblatt1958perceptron}{20}
\bibcite{rumelhart1988learning}{21}
\bibcite{sutskever2014sequence}{22}
\bibcite{waibel1989phoneme}{23}
\bibcite{werbos1990backpropagation}{24}
\bibcite{zeiler2012adadelta}{25}
